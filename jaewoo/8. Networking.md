
## Pod Networking

pod들의 주소 할당 및 통신은 k8s의 자체적인 솔루션으로 구현되지 않는다.

k8s는 모든 pod들이 unique한 ip주소를 가지고, 해당 ip를 통해 같은 node의 모든 pod들이 서로 통신할 수 있도록 한다.

1. node에 container가 생성되면, 네트워크 namespace를 생성한다. k8s는 통신을 위해 namespace를 network에 붙인다. 여기서 말하는 네트워크는 bridge network를 말한다. 즉, 각 노드에 bridge network를 생성한다.
2. 각 bridge network, bridge interface에 ip주소를 할당한다.
3. 컨테이너를 네트워크에 붙인다. pipe 또는 virtual network cable을 사용한다. `ip link add` 명령어를 통해 생성할 수 있다.
   -> pode들이 unique ip를 가졌으며 서로 통신할 수 있다. 다른 노드의 pod와 통신하기 위해서는 아래의 과정이 필요하다.
4. routing table을 이용해 모든 호스트에 대해 route를 구성한다.
5. 위 과정을 manual 하게 script로 정의 하지 않고 자동으로 하기 위해 CNI가 도입되었다. CNI 표준에 맞추어 정의하면, CNI를 통해 위 과정이 수행된다.
## CNI in k8s

kubelet 정보를 통해 CNI 설정 정보를 확인할 수 있다.
`ps -aux | grep kubelet`
- `--network-plugin=cni` : kubelet 실행 시 받은 cni 설정 정보
- `--cni-bin-dir` : cni 플러그인 파일 디렉터리
- `--cni-conf-dir` : cni 설정 파일 디럭터리

-> kubelet은 해당 정보들로 CNI script의 add 명령어를 수행해 네트워크를 구성하게 된다.


## CNI weave

routing table은 수만은 entry를 지원할 수 없다. 클러스터 내 노드가 엄청 많고 각 노드에 pod가 엄청 많은 큰 환셩에서는 다른 솔루션이 필요하다. 이를 weave 등 CNI plugin을 통해 해결할 수 있다.

weave CNI plugin이 클러스터에 배포되면, plugin이 각 노드에 agent 또는 service를 배포 한다. 그들은 노드, network, pod에 대한 정보를 교환하기 위해 서로 통신하다. 각 agent 또는 peer는 전체 설정의 topology를 저장하고, 그렇게 하면 다른 노드에 있는 pod와 해당 ip를 알 수 있다. weave는 노드들에 그만의 bridge를 만들고 weave라고 이름 짓는다. 그리고 각 network에 ip주소를 할당한다.

하나의 pod가 여러개의 bridge network에 붙을 수 있다. 예를 들어 pod가 docker가 만든 docker bridge 뿐만 아니라 weave bridge에도 붙을 수 있다. 패킷이 대상에 도달하기 위해 사용하는 경로는 컨테이너에 구성된 경로에 따라 다르다. weave는 pode들이 agent에 도달할 수 있도록 구성된 올바른 경로를 확보하도록 한다. 그리고 agent가 다른 pod들을 처리한다. 패킷이 하나의 pod에서 다른 노드의 다른 pod로 보내지면, weave는 패킷을 가로채고 별도의 network에 있음을 확인한다. 그런 다음 이 패킷을 새로운 소스 및 대상이 있는 새 패킷으로 캡슐화 하고 네트워크를 통해 전송한다. 다른 쪽에서는, 다른 weave agent가 패킷을 검색하고 분해하여 패킷을 올바른 pod로 라우팅 되게 한다.

## IP Address Management

Pod ip를 중복되지 않도록 할당하는 법.

가장 간단한 방법은 ip 리스트를 파일로 저장하는 것이다. 이 파일을 각 host에 두고 ip를 관리할 수 있다. 하지만 CNI를 통해 다른 방식으로 관리할 수 있다.

weave가 ip주소를 관리하는 방법
weave는 전체 network에 10.32.0.0/12에 해당하는 범위에서 ip를 할당한다. peer가 ip주소를 동등하게 분할하여 각 노드에게 할당한다. 해당 노드에서 생성된 pod는 해당 범위를 가지게 된다.

## Service Networking

svc를 생성하면 다른 node에 있는 pod에도 접근할 수 있다. 하지만, 클러스터 내에서만 접근 가능하다. 이런 svc 타입은 clusterIP이다. 클러스터 외부에서 접근할 수 있도록 노드의 port를 노출하는 방법은 NodePort 타입이다. 그렇다면 서비스들이 ip주소를 어떻게 가지며 ip가 클러스터의 모든 노드에 걸쳐 가능하도록 만들어지는 걸까?

각 노드에는 kube-proxy가 돌고 있다. kube-proxy는 kube-apiserver를 통해 클러스터 내 변화를 관찰하고 있다. 새로운 svc가 생성될 때마다 kube-proxy가 작동한다. pod와 달리 svc는 cluster 범위의 컨셉이다. 그들은 클러스터 내 모든 node에 걸쳐 존재한다.(가상의 객체)

svc가 생성되면 미리 정의된 범위내에서 ip주소가 할당된다. 각 노드에서 돌고 있는 kube-proxy는 ip를 가져와 클러스터 내 각노드에 forwarding rule을 생성한다. (특정 ip로 들어오는 트래픽을 특정 ip로 보내는 rule)

그렇다면 어떻게 kube-proxy가 이 rule들을 생성할까? 여기에는 userspace, iptables, ipvs 세가지 방법이 있다. default는 iptables이다.

`kube-proxy --proxy-mode [userspace | iptables | ipvs] ...`

svc를 생성했을 때 할당되는 clusterIP는 kube-apiserver 옵션을 통해 정의된 범위 내에서 할당된다.
kube-proxy에 의해 생성된 rule은 다음 명령어로 확인 가능하다.

`iptables -L -t nat | grep {SERVICE NAME}`

## DNS

k8s는 기본적으로 built-in DNS 서버를 배포한다. svc가 생성되면 k8s DNS 서버는 svc를 위한 record를 생성한다. 이는 svc 이름과 ip주소를 매핑한다. 따라서 클러스터 내 어느 pod던 svc 이름을 통해 접근할 수 있다. svc가 다른 namespace에 존재하면, {Service Name}.{Namespace}로 도메인이 생성된다.

![[Pasted image 20250406222231.png | 400]]

세모가 svc, 동그라미가 pod다

우리는 svc가 모두 pod로 통신하기 위한 네트워킹 객체인 것은 알고 있다.
svc도 DNS 형태로 접근 가능하다. 

기본 Domain Name
Service
`{Service Name}.{Namespace}.svc.cluster.local`
Pod
`{POD IP with dash}.{Namespaces}.svc.cluster.local`

## CoreDNS in k8s

- k8s가 1.12 부터 추천/배포 하는 DNS 서버
- 클러스터에 kube-system namespace에 배포됨
- CoreDNS 설정은 /etc/coredns/Corefile 에 정의 됨
	- 수많은 plugin들이 정의 되는데, 그 중 CoreDNS가 k8s와 동작하도록 하는 부분은 k8s 부분


## Ingress

ingress는 클러스터 바깥으로부터 svc에 HTTP 또는 HTTPS를 노출한다. 즉, 외부에서 접근가능한 URL을 구성할 수 있다. 동시에 SSL 보안 설정도 제공한다.

>ingree를 위해 사전적으로 ingress controller가 필요하다. ingress-nginx 같은 ingress controller을 배포해야 하며 여러 controller 중 선택하면 된다.

k8s에서 ingresssms L7 수준에서 리버스 프록시 역할을 한다.
엔드유저가 클러스터 내의 어플리케이션에 접근할 때 ingress를 거치게 되고, 이 때 ingress의 rule에 의해서 라우팅 된다.

### ingress controller
- ingress 리소스가 동작하기 위해서는 ingress controller가 반드시 필요
- ingress controller는 자동으로 실행되지 않으며 클러스터에 가장 적합한 컨트롤러를 선택해 구현해야함
- k8s에서 지원하는 prj는 aws, gce, nginx 가 있다.