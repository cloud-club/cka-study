
## Rolling Updates and Rollbacks

### Rollout and Versioning

- Depolyment를 생성하면 Rollout이 트리거 되며 이 rollout은 새로운 deploy revision1을 생성한다.
- Conatiner 버전이 업데이터 되면 새로운 Rollout이 트리거 되며 또다른 deploy revision2가 생성된다.
- 이를 통해 버전 추적이 가능해지고 rollback도 가능해진다.

### Rollout Command

1. Rollout 상태 확인
   `kubectl rollout status deployment/my-app/deployment`
2. Rollout 내역 확인
   `kubectl rollout history deployment/myapp-deployment`

### Deployment Strategy

1. Recreate Strategy
   - 기존 버전을 모두 삭제하고 새로운 버전을 생성하는 전략
   - 무중단 배포를 이루지 못함 Application Down
   - default 아님

2. Rolling Update
   - 하나씩 새버전 업그레이드
   - default

### RollingUpdate Strategy

위의 두 전략은 Deployment 정의 시 `spec.strategy.type`에 지정한다.
즉, `.spec.strategy.type` 필드에 `Recreate` 또는 `RollingUpdate`를 입력할 수 있으며, `RollingUpdate`가 기본 값이다.

만약 `RollingUpdate` 지정 시 `maxUnavailable`과 `maxSurge`를 설정해 업데이트 과정 설정 가능하다.
- `maxUnavailable` : 업데이트 중 이용 불가한 Pod의 최대 개수
- `maxSurge` : 한 번에 생성 가능한 새로운 Pod의 최대 수
   두 옵션 모두 숫자 또는 백분율로 설정 가능
#### Max Unavailable
: 업데이트 중, 이용 불가능한 Pod의 최대 개수

- `.spec.strategy.rollingUpdate.maxUnavailable`은 업데이트 프로세스 중에 사용할 수 없는 최대 Pod의 수를 지정하는 필드이다.
- 해당 값은 5와 같이 특정 개수 명시하거나 10%와 같이 비율로 입력 가능하다. default 는 25%( 75% Pod 사용 보장)
- 만약 `.spec.strategy.rollingUpdate.maxSurge`의 값이 0이면 `Max Unavailable`도 0이 될 수 없다.

만약 ReplicaSet이 10개이고 30%이면
- 10개의 Pod 중 최대 3개까지 Down 가능
- 즉, 업데이트 도중 최소 7개 실행 보장
- 기존 Pod 3개를 종료하고 새 Pod 배포
- 새 Pod 3개가 준비 완료 되면 기존 Pod 중 또 다른 3개 종류 후 또 다른 새 Pod 3개 배포
- 과정 반복으로 전체 Pod 교체
- 

#### Max Surge
: 업데이트 중, 새로 추가되는 최대 Pod 수

- 기본 값 25%
![[Pasted image 20250322011701.png | 700]]
Gpt..

### How update?

update는 여러가지 경우가 있다.
- application
- 사용하는 container version
- label
- replica num
- ...

update 방법은 두가지 있다.

1. `kubectl apply`
   이미 정의 된 yaml 파일 수정 후 apply.
2. `kubectl set image`
   이 방식은 Deployment 라이브 상태만 변경된다. 기존의 .yaml 등의 배포 정의 파일에는 변경 사항이 반영되지 않는다.

yaml을과 일관성 유지를 위해 `kubectl apply` 사용하자

### Update

![[Pasted image 20250322001521.png | 700]]

k8s Deployment 객체가 내부적으로 새 `Replica Set`을 만들고 컨테이너를 배포.

### Rollback

`kubectl rollout undo deployment/myapp-deployment`

새 Replica Set의 Deployment는 새 Replica Set의 Pod를 파괴 하고 
이전 버전 Seplica Set의 예전 Pod들을 불러온다.


##  docker Commands

`docker run ubuntu [COMMAND]` 이런식으로 코멘트 지정이 가능하다. 또는 DockerFile을 열어 CMD 부분 수정이 가능하다.

`CMD ["sleep", "5"]` 이런식으로. 그리고 코멘트와 value는 분리되어야 한다.
`CMD ["sleep 5"]` 이게 안된다는 이야기 이다.

그러면 `CMD ["sleep"]` 으로 지정되어 있고 `docker run ubuntu-sleeper 10` 이렇게 하면  sleep 10이 실행 될까?  -> 실행 된다.

명령줄에 명시되지 않는 명령줄을 보통 실행 시킬때

```Dockerfile
FROM ubuntu
ENTRYPOINT ["sleep"]
CMD ["5"]
```
이렇게 쓴다. 이러면 ENTRYPOINT가 기본 명령줄이 되고 CMD의 값이 기본 명령 value가 되어서 아무것도 지정하지 않아도 돌아간다.

그냥 `docker run ubuntu` 실행할 프로그램이 없기 때문에 컨테이너가 종료된다.
컨테이너는 내부의 프로세스가 살아 있어야 된다.



### CMD & ENTRYPOINT 추가 설명

`docker run [이미지이름] [전달할 인자]`

- `docker run [이미지]` 를 통해 컨테이너 실행
- 이미지 내부에서 실행할 프로그램을 CMD나 ENTRYPOINT로 지정
- CMD -> 기본 명령 실행
- ENTRYPOINT -> 실행할 프로그램 고정


#### CMD
- 실행할 프로그램과 인자 설정 가능
- 실행 시 덮어씌울 수 있음
- 단순한 기본값 지정 용도로 사용

```dockerfile
FROM ubuntu
CMD ["sleep", "5"]
```

```sh
docker run my-container    # sleep 5 (기본 값 실행)
docker run my-container 10 # sleep 10 (CMD 덮어씌움)
```

#### ENTRYPOINT
- 실행할 프로그램 고정
- 실행 시 매개변수만 변견 가능
- 특정 프로그램을 강제할 때 사용

```dockerfile
FROM ubuntu
ENTRYPOINT ["sleep"]
CMD ["5"]
```

```sh
docker run my-container    # sleep 5 (기본 값 실행)
docker run my-container 10 # sleep 10 (CMD 만 변경)
docker run my-container ls # sleep ls 실행 (에러)
```

--entrypoint 옵션으로 재정의 가능


## k8s commands & args

docker의 command 개념을 k8s에서도 사용한다. `command`가 `entrypoint` 역할이고, `args`가 `CMD` 역할이다.

만약 컨테이너 이미지에 `entryPoint`, `CMD`가 있는데 k8s의 `command`, `args`가 지정되었다면 k8s의 설정만 수행된다. 오버라이드 된다.

```yml
...
spec: 
	containers: - name: ubuntu-sleeper 
	- image: ubuntu-sleeper 
	  command: ["sleeper덮어쓰기"] #Docker의 ENTRYPOINT와 동일 
	  args: ["10"] #Docker의 CMD란과 동일 
	restartPolicy: OnFailure
```


## 환경 변수
이렇게 command와 args를 활용해서 pod하나하나 값을 지정할 수 있지만 여러 파드에 이 작업이 필요한 경우 공통으로 환경변수를 지정해서 쓸 수 있다. 여기엔 세 가지 방법이 있다.
- ENV
- ConfigMap
- Secrets

### ENV
원하는 값을 env라는 필드 아래에 key-value 형태로 입력하는 것.

### ConfigMap

configMap 오브젝트를 사용해서 호출하는 방식. 여러 Pod가 하나의 ConfigMap을 볼 때 변경 사항을 관리하기 용이하다.
먼저 configMap 오브젝트를 생성하고 그 뒤에 해당 오브젝트를 사용할 Pod manifest에서 부르는 방식이다.


![[Pasted image 20250322133008.png | 500]]

#### configMap 생성
- Imperative:
`kubectl create configmap <config-name> --from-literal=<key>=<value>`
`kubectl create configmap app-config --from-literal=APP_COLOR=blue --from-literal=APP_MODE=prod`

`kubectl create configmap <config-name> --from-file=<path-to-file>`
`kubectl create configmap app-config --from-file=app_config.properties`

- Declarative:
`kubectl create -f`
```yml
apiVersion: v1
kind: ConfigMap
metadata:
	name: app-config
data:
	APP_COLOR: blue
	APP_MODE: pord
```

#### configMap 호출

1. ENV:  변수 여러 개여서 configMap을 전체 다 호출할 때
```yml
envFrom:
- configMapRef:
	  name: app-config
```

2. singleEnv: configMap 값 중 하나만 부를 때
```yml
env:
- name: APP_COLOR
  valueFrom:
	  configMapKeyRef:
		  name: app-config
		  key: APP_COLOR
```

3. volume
```yml
volumes:
- name: app-config-volume
  configMap:
	  name: app-config
```


### Secrets

Secrets는 base64를 사용해 암호화 해서 key-value를 저장하는 오브젝트이다. 외부로 노출되면 안되는 것을 저장할 때 이용한다.

configMap과 동일하게 오브젝트 생성 후 호출하여 사용한다.

>base64로 인한 암호화는 그다지 안전하지 않기에 valut나 AWS Secrets Manager등을 사용한다.

#### Secret 생성
- imperative:
  `k create secret generic <secret-name> --from-literal=<key>=<value>`
  `k create secret generic <secret-name> --from-file=<path>`

- Declarative
```yml
apiVersion: v1
kind: Secret
metadata:
	name: app-secret
data:
	DB_HOST: mysql
	DB_User: root
	DB_Password: p@ssw0rd
```

#### Secret 호출
- ENV
```yml
envFrom:
- secretRef:
	  name: app-config
```

- SingleENV
```yml
env:
- name: DB_Password
  valueFrom:
	  name: app-secret
	  key: DB_Password
```

- Volumes:
```yml
volumes:
- name: app-secret-volume
  secret:
	  secretName: app-secret
```


## Configure Secrets in Application

Secret은 사용 방법이나 동작 과정이 ConfigMap과 동일 하지만, 민감한 정보를 그대로 노출하지 않겠다는 것에 목적이 있음
즉, ConfigMap 처럼 값을 공개적으로 확인하는 것이 어렵게 유지하여 ConfigMap이랑 역할 분리하는 것.

생성법은 위에서 참고

Declarative방식으로 저장 시 정의 파일 내에 키와 값이 Plain Text로 저장되어 확인이 쉬워지지 않는 문제가 있다.
따라서 정의 파일 운용 시 인코딩 된 값을 기재해야 한다.
`echo -n ${TEXT} | base64`

imperative 방식은 별도 파일이 존재하지 않으니 인코딩 없이 생성.

Secret으로 생성된 값을 확인하고 싶으면 yaml파일을 확인하면 된다.

1. `k get secret ${NAME} -o yaml`
2. `echo -n ${TEXT} | base64 --decode`

로 값을 읽어낸다.

> 위에서 base64가 안전하지 않다고 말했 듯이 어디까지나 인코딩 된 것이지, 암화화가 아니다.

내부 이용자의 접근성 감소가 목적이지, 접근 자체를 막는게 아니다.
따라서 진짜 막고 싶으면 서드파티 업체가 제공하는 서비스 이용해야 된다.

### Encryption

별도의 암호화 설정이 없다면 ETCD의 API를 이용하여 k8s 내부에서 이용하는 Secret의 값을 Plain Text로 확인할 수 있다.

```bash
apt-get install etcd-client 

ETCDCTL_API=3 etcdctl \ 
—cacert=/etc/kubernetes/pki/etcd/ca.crt \ 
—cert=/etc/kubernetes/pki/etcd/server.crt \ 
—key=/etc/kubernetes/pki/etcd/server.key \ 
get /registry/secretes/default/${SECRET_NAME} | hexdump -C
```

만일 암호화가 되어 있지 않다면, kube API Server 실행에  `--encryption-provider-config`의 설정이 되어 있지 않은 것.

출력 내용 확인 
- `ps -aux | grep 'kube-api' | grep 'encryption-provider-config` 
- `cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep ‘encryption-provider-config’

만약 출력 내용이 없다면 별도 `EncryptionConfiguration` 객체를 만들어 이를 kube API Server의 `--encryption-provider-config` 실행 옵션으로 기재해야 한다.
이 때 `EncryptionConfiguration`의 resources라는 암호화 대상은 Secret 뿐만 아니라 다른 k8s 객체도 지정할 수 있는데 대체로 Secret만 지정하는 것이 좋으며, providers 항목에는 암호화 방식에 대해 명시할 수 있음

providers에서 사용하는 암호화 방식에는 암호화에 사용할 키를 명시해야함. 아래 명령어로 생성가능
`head -c 32 /dev/urandom | base64`

```yml
apiVersion: apiserver.config.k8s.io/v1 
kind: EncryptionConfiguration 
resources: 
- resources: 
	- secrets 
	  providers: 
	  - aescbc: 
			keys: 
			- name: key1
				secret: ${RANDOM_VALUE_32_BYTES}
```

위와 같은 파일을 `/etc/kubernetes/enc` 에 작성

`vim /etc/kubernetes/manifests/kube-apiserver.yaml`을 통해 Kube API Server를 아래와 같은 형태로 수정

```yml
apiVersion: v1 
kind: Pod 
metadata: 
	annotations: 
		kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.20.30.40:443 
	creationTimestamp: null 
	labels: 
		app.kubernetes.io/component: kube-apiserver 
		tier: control-plane 
	name: kube-apiserver 
	namespace: kube-system 
spec: 
	containers: 
	- command:
	   - kube-apiserver 
	     ... 
	     # ADD BELOW WITH FILE NAME FROM HERE
	     - --encryption-provider-config=/etc/kubernetes/enc/${ENCRYPTION_CONFIGURATION_FILE_NAME}.yaml 
	    # TO HERE volumeMounts: 
	    ... 
	    # ADD BELOW FROM HERE 
	    - name: enc 
	      mountPath: /etc/kubernetes/enc 
	      readOnly: true 
	      # TO HERE ... 
		volumes: 
		... 
		# ADD BELOW FROM HERE 
		- name: enc 
		  hostPath: 
			  path: /etc/kubernetes/enc 
			  type: DirectoryOrCreate 
			# TO HERE 
			...
```

위 파일의 저장과 동시에 kube API Server는 재실행 되고, `--encryption-provider-config` 옵션 확인해보면 된다.

이전 과정과 마찬가지로 Secert 객체를 만들고, ETCD API를 이용해 잘 암호화 되었다면 기능이 정상 작동할 것이다.

**암호화 이전 생성 secret은 적용되지 않음.

자세한 내용은 [참고블로그](https://www.jseo.cc/22930690-c255-409f-b441-04097d503515)

**보안 향상 가이드

- secret 객체 정의 파일을 소스 코드 저장소에 저장 X
- ETCD에 저장될 때 Secret이 암호화 되도록 Encryption ad Rest 기능 활성화

k8s의 보안적 특징
- 특정 Node에서 실행 중인 PO가 해당 Secret을 필요로 할 때만 그 Node로 Secret 전송
- kubelet이 Secret을 tmpfs(메모리 기반 fs)에 저장하여 디스크에 저장 X
- Secret을 사용하는 Pod가 삭제되면 kubelet이 로컬에 저장된 Secret도 삭제

동영상

## Demo: Encrypting Secret Data at Rest

[참고](###encryption)

## Multi Container Pods & Design Patterns

Application 2개가 서로 역할과 기능이 달라 코드 상 분리가 되어야 하지만, 두 기능이 함께 동작해야 하는경우( lifecycle 공유) 여러 컨테이너가 포함된 Pod 생성 가능

- SideCar
- Adapter
- Ambassador
#### Scaling
여러 컨테이너가 한 Pod에 있을 때 Scaling 역시 ReplicaSet을 이용할 수 있음
ReplicaSet을 이용하는 Deployment를 사용하게 되면 Scaling을 만족함과 동시에 Rolling Update , Rollback도 가능

#### Init Container
예를 들어 한 Pod에 A,B 컨테이너 구성한다면, 두 컨테이너는 라이프사이클을 동일하게 유지
실행 순서 지정하고 싶으면 `InitContainers` 옵션으로 지정 가능. 기재된 컨테이너들 구성 실패 시 Pod의 재실행.

#### Self Healing
Replica Set 및 Replication Controller에 의해 Pod가 관리되도록 구성하면, Pod로 구성된 어플리케이션들은 문제가 생겼을 때 정해진 수의 Pod를 만족시키기 위해 자체적으로 Pod를 생성하는 과정을 거치면서 Self Healing을 수행.

## Autoscaling

전통적인 autoscaling에는 수직, 수평 확장

k8s
- Scaling Workloads :  cluster의 컨테이너, Pod 조절
	- 수평 : pod 추가 : `kubectl scale`
	- 수직 : 기존 pod 리소스 추가 `kubectl edit`
	- HPA, VPA

- Scaling Cluster Infra : cluset 자체 확장 
	- 수평 : Node 추가 : `kubeadm join`
	- 수직: 기존 Node 리소스 추가
	- 수직적 확장은 실행 중인 애플리케이션을 중단 후 리소스 증가 후 재실행 해야 하므로 k8s 와 어울리지 않음
	- 보통 cloud 상에서 돌아가므로 더 큰 리소스를 가진 서버에 프로비저닝 하여 클러스터에 추가 후 기존 제거
	- Cluster Autoscaler

## Horizontal Pod Autoscaler


manual way
- metrics Server을 통해 Top 명령어로 리소스 확인
- 임계값에 가까워 지면 `kubectl scale`을 통해 증설
- 귀찮고, 빠른 대응 불가

#### HPA

- Observers metrics
- Add Pods
- Balances thresholds
- Tracks multiple metrics

`kubectl autoscale deployment my-app --cpu-percent=50 --min=1 --max=10`

k8s 내부 metrics Server을 이용하는 방법이고, 외부 dataDog이나 Dynatrace를 활용할 수도 있음

## In-place Resize of Pods

Pod Resize를 하면 기존엔 Pod를 죽이고 다시 구동시켰다.
1.33 부터 resizePolicy를 통해 이를 지정해서 재시작 여부를 설정할 수 있다.

그러나 아직 정식 지원하지 않음
- cpu, memory의 requests만 변경 가능하며 limits은 안됨
- 메모리 요청량을 줄일 수 있지만 OOM이 발생할 수 있다.

## Vertical Pod Autoscaling

manual
- HPA와 동일

#### VPA

- Observers metrics
- Balances thresholds
- Tracks multiple metrics

VPA는 기본 제공되지 않고 git에서 받아야함.
구성요소는 다음과 같다.
- VPA Admission Controller : Recommender의 권장사항을 토대로 Pod 재구동
- VPA Updater : 업데이트 필요시 Recommender의 도움을 받아 Pod 종료
- VPA Recommender : Metrices Server에서 데이터 수집 및 권장 사항 제공. 직접 수정 X

VPA type

| Mode     | Description                            |
| -------- | -------------------------------------- |
| off      | Only recommends                        |
| initial  | only changes on pod creation           |
| Recreate | Evicts pods if usage goes beyond range |
| Auto     | Updates existing pods to recommendeds  |
Recreate와 Auto 모드는 거의 동일하게 구동된다.
Auto 모드는 위의 In-place Resize of Pods를 염두해서 만든 모드이다.


#### HPA vs VPA

| Feature             | VPA                            | HPA                                             |
| ------------------- | ------------------------------ | ----------------------------------------------- |
| Scaling Method      | 개별 Pod 성능 최적화                  | 여러 인스턴스에 부하 분산                                  |
| Pod Behavior        | Pod 재실행                        | Pod 실행 유지                                       |
| Traffic 폭등 Handles? | X. pod 재시작이 필요하기 때문            | O                                               |
| 비용 최적화              | 실제 사용량에 맞게 Pod 설정 가능           | 유휴 pod 방지                                       |
| Best For            | StateFul Workload<br>리소스 큰 app | webb app<br>microservices<br>stateless service |



